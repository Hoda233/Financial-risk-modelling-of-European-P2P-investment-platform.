{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdd7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffe1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the whole output result\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd42a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../dataset/Bondora_raw.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71e0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data features/columns alphabitcally\n",
    "data = data.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data dimensions\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935bccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show data info (columns' names, data types,...)\n",
    "print(data.info(verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9012d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data description (count, mean, std, min, max,...) for numerical features\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2be7e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show data unique values counts\n",
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c5caf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9   ActiveLateCategory\n",
      "[nan '180+' '16-30' '1-7' '31-60' '8-15' '121-150' '91-120' '151-180'\n",
      " '61-90']\n",
      "9   ActiveLateLastPaymentCategory\n",
      "[nan '180+' '151-180' '31-60' '8-15' '1-7' '91-120' '16-30' '121-150'\n",
      " '61-90']\n",
      "2   ActiveScheduleFirstPaymentReached\n",
      "[ True False]\n",
      "24   ApplicationSignedHour\n",
      "[17 20 12 10 16  9 18 22 11 15  0 13 23 19 14  8 21  7  1  2  6  3  5  4]\n",
      "7   ApplicationSignedWeekday\n",
      "[5 4 6 7 1 3 2]\n",
      "4   Country\n",
      "['EE' 'FI' 'ES' 'SK']\n",
      "7   CreditScoreEeMini\n",
      "[  nan 1000.  700.  800.  600.  900.  500.    0.]\n",
      "6   CreditScoreEsEquifaxRisk\n",
      "[nan 'A' 'AA' 'B' 'C' 'AAA' 'D']\n",
      "11   CreditScoreEsMicroL\n",
      "[nan 'M3' 'M5' 'M1' 'M9' 'M2' 'M6' 'M4' 'M8' 'M7' 'M10' 'M']\n",
      "14   CreditScoreFiAsiakasTietoRiskGrade\n",
      "[nan 'RL2' 'RL1' 'RL4' 'RL3' 'RL0' 'RL5' '2' '1' '3' '4' '5' '6' '7' '8']\n",
      "7   Education\n",
      "[ 3.  5.  4.  2.  1.  0. nan -1.]\n",
      "9   EmploymentDurationCurrentEmployer\n",
      "['UpTo3Years' 'MoreThan5Years' 'UpTo4Years' 'UpTo2Years' 'UpTo1Year' nan\n",
      " 'UpTo5Years' 'TrialPeriod' 'Other' 'Retiree']\n",
      "7   EmploymentStatus\n",
      "[ 3. nan  2.  4.  5.  6.  0. -1.]\n",
      "39   ExistingLiabilities\n",
      "[ 0  6  4  1  8  3  2  5  7  9 10 12 11 15 14 17 13 16 18 24 19 26 23 20\n",
      " 21 22 25 27 36 30 28 35 29 31 32 33 34 39 40]\n",
      "3   Gender\n",
      "[ 1.  0.  2. nan]\n",
      "12   HomeOwnershipType\n",
      "[nan  0.  4.  2.  1.  3.  5.  8.  6.  7.  9. 10. -1.]\n",
      "13   LanguageCode\n",
      "[ 1  3  2  4  6 22 15  9  5 10 13  7 21]\n",
      "31   LoanDuration\n",
      "[12  1 20 15 24  6  2  5  3 10 18  4 17  9 13  7 14  8 22 16 11 19 60 21\n",
      " 36 48 30 42 27 52 38]\n",
      "7   MaritalStatus\n",
      "[ 1.  4.  3.  2.  5.  0. nan -1.]\n",
      "7   ModelVersion\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.]\n",
      "29   MonthlyPaymentDay\n",
      "[25 15  9  3  1 10 28 24 20 23 11 18 12  5 26 22 16  2  7 13  6 21 14 19\n",
      "  8 27 17  4  0]\n",
      "2   NewCreditCustomer\n",
      "[ True False]\n",
      "26   NextPaymentDate\n",
      "[nan '2020-02-17' '2020-02-10' '2020-02-25' '2020-02-03' '2020-02-11'\n",
      " '2020-01-28' '2020-02-05' '2020-02-27' '2020-02-21' '2020-02-20'\n",
      " '2020-02-07' '2020-02-12' '2020-03-02' '2020-02-14' '2020-02-19'\n",
      " '2020-02-13' '2020-02-04' '2020-02-26' '2020-02-18' '2020-02-06'\n",
      " '2020-02-24' '2020-03-09' '2020-03-11' '2020-03-06' '2020-03-10'\n",
      " '2020-03-05']\n",
      "26   NoOfPreviousLoansBeforeLoan\n",
      "[ 1  2  0  3  4  5  9  8  7  6 11 10 13 20 12 14 15 16 17 18 19 21 22 23\n",
      " 24 25]\n",
      "11   NrOfDependants\n",
      "['0' '1' '3' '2' '5' '4' nan '6' '10Plus' '7' '10' '8']\n",
      "21   OccupationArea\n",
      "[ 7. 16.  9.  1. 10. 12.  8.  6. 11. 17.  5.  4.  3. 19. nan  0. 18. 15.\n",
      " 13. 14.  2. -1.]\n",
      "11   PreviousEarlyRepaymentsCountBeforeLoan\n",
      "[ 0  1  2  3  7  4  5  6  8  9 11]\n",
      "8   Rating\n",
      "[nan 'F' 'C' 'HR' 'D' 'E' 'B' 'A' 'AA']\n",
      "8   Rating_V0\n",
      "[nan 'HR' 'A' 'F' 'C' 'D' 'B' 'AA' 'E']\n",
      "8   Rating_V1\n",
      "[nan 'F' 'C' 'HR' 'D' 'E' 'B' 'A' 'AA']\n",
      "8   Rating_V2\n",
      "[nan 'D' 'B' 'HR' 'F' 'C' 'E' 'A' 'AA']\n",
      "2   RecoveryStage\n",
      "[nan  2.  1.]\n",
      "21   RefinanceLiabilities\n",
      "[ 0  2  1  3  5  4  6  7  8  9 10 11 12 13 14 17 19 16 15 18 23]\n",
      "1   ReportAsOfEOD\n",
      "['2020-01-27']\n",
      "2   Restructured\n",
      "[False  True]\n",
      "3   Status\n",
      "['Repaid' 'Late' 'Current']\n",
      "17   UseOfLoan\n",
      "[  7   2   0   6   8   3   5   4   1 110 101 102 104 108 106 107  -1]\n",
      "5   VerificationType\n",
      "[ 2.  4.  1.  3.  0. nan]\n",
      "6   WorkExperience\n",
      "['MoreThan25Years' '2To5Years' '5To10Years' '15To25Years' '10To15Years'\n",
      " 'LessThan2Years' nan]\n",
      "9   WorseLateCategory\n",
      "['91-120' nan '180+' '31-60' '151-180' '61-90' '1-7' '121-150' '16-30'\n",
      " '8-15']\n"
     ]
    }
   ],
   "source": [
    "# show data unique values if they are less than 40 values\n",
    "for column in data:\n",
    "    unique_count = data[column].nunique()\n",
    "    if(unique_count <= 40):\n",
    "        print(unique_count, ' ', column)\n",
    "        print(data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc959d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show data null counts\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc44b3ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object   90.91720000892 %   CreditScoreEsEquifaxRisk\n",
      "object   75.82826007775274 %   CreditScoreFiAsiakasTietoRiskGrade\n",
      "float64   96.60370626407689 %   EL_V0\n",
      "float64   90.39463610076638 %   EL_V1\n",
      "object   86.0342379709951 %   GracePeriodEnd\n",
      "object   86.0342379709951 %   GracePeriodStart\n",
      "object   96.60370626407689 %   Rating_V0\n",
      "object   90.39463610076638 %   Rating_V1\n",
      "object   81.31034944138439 %   Rating_V2\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# show data null counts with percentage more than 70%\n",
    "count=0 \n",
    "for column in data:\n",
    "    nulls_percentage = (data[column].isnull().sum()/data.shape[0])*100\n",
    "    if(nulls_percentage > 75 ):\n",
    "        print(data[column].dtype,' ', nulls_percentage,'%',' ' ,column)\n",
    "        count=count +1\n",
    "print(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5853ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature column which has null counts with percentage more than 70%\n",
    "dropped_nulls_features=[]\n",
    "for column in data:\n",
    "    nulls_percentage = (data[column].isnull().sum()/data.shape[0])*100\n",
    "    if(nulls_percentage > 75):\n",
    "        dropped_nulls_features.append(column) \n",
    "        \n",
    "new_data = data.drop(dropped_nulls_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1420194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature that are unique foe each row \n",
    "dropped_unique_features=['LoanId','LoanNumber']\n",
    "new_data = new_data.drop(dropped_unique_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da80031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature that has only one value \n",
    "new_data = new_data.drop('ReportAsOfEOD', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e8043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numerical features\n",
    "numerical_columns = []\n",
    "for column in new_data:\n",
    "    if(new_data[column].dtype == 'float64' or new_data[column].dtype == 'int64'):\n",
    "        numerical_columns.append(column)\n",
    "\n",
    "# get categorical features\n",
    "categorical_columns = []\n",
    "for column in new_data:\n",
    "    if(new_data[column].dtype == 'object'):\n",
    "        categorical_columns.append(column)  \n",
    "        \n",
    "# get boolean features\n",
    "boolean_columns = []\n",
    "for column in new_data:\n",
    "    if(new_data[column].dtype == 'bool'):\n",
    "        boolean_columns.append(column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ed0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace -1 with null to be handled as missing value\n",
    "for num_column in numerical_columns:\n",
    "    new_data[num_column] = new_data[num_column].replace(-1., np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a291b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# handle missing values for numerical features\n",
    "for num_column in numerical_columns:\n",
    "    mean_value = new_data[num_column].mean()\n",
    "    new_data[num_column].fillna(mean_value,inplace=True)\n",
    "#     print(num_column,' ' , new_data[num_column].isnull().sum())\n",
    "\n",
    "# bool\n",
    "for bool_column in categorical_columns:\n",
    "    mode_value = new_data[bool_column].mode().values[0]\n",
    "    new_data[bool_column].fillna(mode_value,inplace=True)\n",
    "    \n",
    "# cat\n",
    "for cat_column in boolean_columns:\n",
    "    mode_value = new_data[cat_column].mode().values[0]\n",
    "    new_data[cat_column].fillna(mode_value,inplace=True)\n",
    "#     print(cat_column,' ' , new_data[cat_column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean to int\n",
    "for bool_column in boolean_columns:\n",
    "    new_data[bool_column] = new_data[bool_column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features with values that contain date + time to contain only date\n",
    "date_time_features = ['BiddingStartedOn','LoanApplicationStartedDate','ListedOnUTC','StageActiveSince']\n",
    "for col in date_time_features:\n",
    "    new_data[col] = new_data[col].str.split().str[0]\n",
    "    \n",
    "print(new_data[date_time_features].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00eab32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapping = {'1-7': 1, '8-15': 2, '16-30': 3, '31-60': 4, '61-90': 5, '91-120': 6, '121-150': 7, '151-180': 8, '180+': 9}\n",
    "\n",
    "features = ['ActiveLateCategory','ActiveLateLastPaymentCategory','WorseLateCategory']\n",
    "new_data[features] = new_data[features].replace(mapping)\n",
    "\n",
    "for col in features:\n",
    "    print(new_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475edebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = { 'LessThan2Years':1,'2To5Years':2,'5To10Years':3,'10To15Years':4,'15To25Years':5,'MoreThan25Years':6}\n",
    "\n",
    "new_data['WorkExperience'] = new_data['WorkExperience'].replace(mapping)\n",
    "\n",
    "print(new_data['WorkExperience'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a19302a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreditScoreEsMicroL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCreditScoreEsMicroL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreditScoreEsMicroL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   5908\u001b[0m     ]\n\u001b[0;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1154\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1151\u001b[0m \n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# work around NumPy brokenness, #1987\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[1;32m-> 1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype_intsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[1;32mF:\\anaconda\\lib\\site-packages\\pandas\\_libs\\lib.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "new_data['CreditScoreEsMicroL'] = new_data['CreditScoreEsMicroL'].str[1:].astype(int)\n",
    "\n",
    "print(new_data['CreditScoreEsMicroL'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27316cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'TrialPeriod':0,'UpTo1Year':1,'UpTo2Years':2,'UpTo3Years':3,'UpTo4Years':4,'UpTo5Years':5,'MoreThan5Years':6,'Retiree':7,'Other':8}\n",
    "\n",
    "new_data['EmploymentDurationCurrentEmployer'] = new_data['EmploymentDurationCurrentEmployer'].replace(mapping)\n",
    "\n",
    "print(new_data['EmploymentDurationCurrentEmployer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16eb062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '3' '2' '5' '4' nan '6' '10' '7' '8']\n"
     ]
    }
   ],
   "source": [
    "new_data['NrOfDependants'] = new_data['NrOfDependants'].str[:2].astype(int)\n",
    "\n",
    "print(new_data['NrOfDependants'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aa790aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  7.  4.  8.  5.  6.  3.  2.  1.]\n"
     ]
    }
   ],
   "source": [
    "mapping = {'AA':1,'A':2,'B':3,'C':4,'D':5,'E':6,'F':7,'HR':8  }\n",
    "\n",
    "new_data['Rating'] = new_data['Rating'].replace(mapping)\n",
    "\n",
    "print(new_data['Rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d39538",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'EE':1,'FI':2,'ES':3,'SK':4}\n",
    "\n",
    "new_data['Country'] = new_data['Country'].replace(mapping)\n",
    "\n",
    "print(new_data['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374610b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get numerical features\n",
    "numerical_columns = []\n",
    "for column in new_data:\n",
    "    if(new_data[column].dtype == 'float64' or new_data[column].dtype == 'int64'):\n",
    "        numerical_columns.append(column)\n",
    "\n",
    "# get categorical features\n",
    "categorical_columns = []\n",
    "for column in new_data:\n",
    "    if(new_data[column].dtype == 'object'):\n",
    "        categorical_columns.append(column)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700ad84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2796784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outliers_handling(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    lower_range = Q1 - 1.5 * (Q3 - Q1)\n",
    "    upper_range = Q3 + 1.5 * (Q3 - Q1)\n",
    "    column = np.where(column > upper_range, upper_range, column)\n",
    "    column = np.where(column < lower_range, lower_range, column)\n",
    "    return column\n",
    "\n",
    "for num_column in numerical_columns:\n",
    "    new_data[num_column] = outliers_handling(new_data[num_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_column in numerical_columns:\n",
    "    new_data[num_column].fillna(new_data[num_column].mean(),inplace=True)\n",
    "    print(num_column,' ' , new_data[num_column].isnull().sum())\n",
    "    \n",
    "for cat_column in categorical_columns:\n",
    "#     print(cat_column,' ' , new_data[cat_column].isnull().sum())\n",
    "    new_data[cat_column].fillna(new_data[cat_column].mode().values[0],inplace=True)\n",
    "    print(cat_column,' ' , new_data[cat_column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156b57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9ee08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9dde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in new_data:\n",
    "    unique_count = new_data[column].nunique()\n",
    "    if(unique_count <= 40):\n",
    "        print(unique_count, ' ', column)\n",
    "        print(new_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695938f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
